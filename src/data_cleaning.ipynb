{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of COVID impact on US household - Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Motivation </h3> \n",
    "\n",
    "<p>The goal of this analysis is to gauge the impact of the pandemic on overall household characteristics such as employment status, housing, education disruptions, and dimensions of physical and mental wellness. There is a large amount of emotionally negative stimuli related to the COVID-19 pandemic. How do people prepare themselves in difficult times like this? Analyzing and exploring people's response to pandemic can provide useful insights into people's perspective about COVID and the challenges they face.</p>\n",
    "\n",
    "<p>As we all know,the impacts of the pandemic and the economic fallout have been widespread, but are particularly prevalent among Black, Latino, Indigenous, and immigrant households. There is also an impact on gender. This analysis will deep dive into some of the impacts of COVID by Age group, race and ethinicity, and gender. We also try to understand the different groups of people based on various characteristics pertaining to COVID. The research questions will target specific variables. Below are some references that tracks the COVID impacts: </p>\n",
    "<li><a href='https://www.cbpp.org/research/poverty-and-inequality/tracking-the-covid-19-recessions-effects-on-food-housing-and'>Covid Recession effects</a></li>\n",
    "<li><a href='https://www.cdc.gov/nchs/covid19/pulse/mental-health.htm'>Covid data from NCHS</a></li>\n",
    "\n",
    "\n",
    "<h3>Data Source</h3>\n",
    "<p>The <a href='https://www2.census.gov/programs-surveys/demo/technical-documentation/hhp/2020_HPS_Background.pdf'>Household Pulse Survey</a> provides timely data to help understand the experiences of American households during the coronavirus pandemic. Data for this analysis is obtained from the Phase 1 Household Pulse Survey that began on April 23 and ended on July 21, 2020. The dataset is very rich and informative. It dataset has 105 variables, 1088314 observations and includes employment status, food security, housing, physical and mental health, access to health care, and educational disruption. In order to support the nation’s recovery, we need to know the ways this pandemic has affected people’s lives and livelihoods. Data from these datasets will show the widespread effects of the coronavirus pandemic on individuals, families, and communities across the country. </p>\n",
    "\n",
    "<p>The survey was conducted by an internet questionnaire, with invitations to participate sent by email and text message. Housing units linked to one or more email addresses or cell phone numbers were randomly selected to participate, and one respondent from each housing unit was selected to respond. All the data has been de-identified.</p>\n",
    "\n",
    "<h4> Links to Data set and Data dictionary</h4>\n",
    "<ul><li>The Phase 1 survey datasets are available for public use under <a href='https://www.census.gov/programs-surveys/household-pulse-survey/datasets.html'>census.gov</a> website as weekly files.</li>\n",
    "<li>Data dictionary is available in the census.gov website under the link <a href='https://www.census.gov/programs-surveys/household-pulse-survey/technical-documentation.html#phase1'>Phase 1 Household Pulse Survey Technical Documentation</a></li></ul>\n",
    "\n",
    "<h4>Download data</h4>\n",
    "<p>Data is directly downloaded from census website using zipfile package<p>\n",
    "  \n",
    "\n",
    "<h4>Terms of use of census data </h4>\n",
    "<p>The Census Bureau is committed to open government by sharing its public data as open data. Census data continues to be a key national resource, serving as a fuel for entrepreneurship and innovation, scientific discovery, and commercial activity.  We continuously identify and publish datasets and Application Programming Interface’s (API’s) to Data.gov in accordance with the Office of Management and Budget (OMB) Memorandum M-10-06, the Executive Order 13642 on open data, and the overall principles outlined in the Digital Government Strategy.  In\n",
    " accordance with the Open Data Policy, M-13-13, the Census Bureau publishes its information in machine-readable formats while also safeguarding privacy and security.</p>\n",
    " \n",
    " \n",
    " <h3>Research Questions</h3>\n",
    "<ul>\n",
    "    <li>Understand the impacts of COVID in terms of employment loss, income loss, food insufficiency, education interruptions, inability to meet housing expenses and how does this vary by Race/Ethnicity or gender? </li>\n",
    "    <li>What is the impact on Mental health status (Anxiety and depression)? Is there a correlation between Mental health status (Anxiety and depression) and factors such as age, number of household members, gender, income, health status, race? How does the anxiety levels vary between first and last week of survey?</li>\n",
    "    <li>How does employment loss, income loss, food insufficiency, education interruptions, inability to meet housing expenses in Washington differ as compared  to national average?</li>\n",
    "    <li>How do different groups based on age, race and ethnicity differ in their behavior or attitude towards COVID. Are there any patterns observed in the population based on certain characteristics pertaining to COVID?</li> \n",
    "</ul>\n",
    "\n",
    "\n",
    "<h3>Methodology</h3>\n",
    "<p>For all the research questions, multivariate analysis will be used.</p>\n",
    "<p><strong>Statistical Analysis Method</strong>\n",
    "<ul><li>Regression analysis will be used to train and determine the impactful predictors. This method is appropriate as all the data points are independent and the sample size is large enough to meet the normality assumption. As the dataset has both numerical and categorical data, regression techniques are suitable. The model is also interpretable.</li>\n",
    "<li>Clustering will be used to identify any patterns and classify groups of people based on similar characteristics</li></ul>\n",
    "<li><strong>Results</strong>\n",
    "    The results will be presented in a comprehensive compilation of visualizations.</li></p>\n",
    "\n",
    "<h3>Source of Bias</h3>\n",
    "<p> Nonsampling errors can also occur and are more likely for surveys that are implemented quickly, achieve low response rates, and rely on online response.  Nonsampling errors for the Household Pulse Survey may include:</p>\n",
    "\n",
    "<ul><li><strong>Measurement error:</strong> The respondent provides incorrect information, or an unclear survey question is misunderstood by the respondent. The Household Pulse Survey schedule offered only limited time for testing questions. </li>\n",
    "<li><strong>Coverage error: </strong>Individuals who otherwise would have been included in the survey frame were missed. The Household Pulse Survey only recruited households for which an email address or cell phone number could be identified.</li>\n",
    "<li><strong>Nonresponse error:</strong> Responses are not collected from all those in the sample or the respondent is unwilling to provide information. The response rate for the Household Pulse Survey was substantially lower than most federally sponsored surveys.</li>\n",
    "<li><strong>Processing error: </strong>Forms may be lost, data may be incorrectly keyed, coded, or recoded. The real-time dissemination of the Household Pulse Survey provided limited time to identify and fix processing errors.</li>\n",
    " \n",
    "<p>The Census Bureau employs quality control procedures to minimize these errors.  However, the potential bias due to nonsampling errors has not yet been evaluated.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Exploratory Data Analysis </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import Packages</h3>\n",
    "<p> Import all the required packages</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# packages required for proecessing zip files\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# packages for plots and graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Download data from census.gov</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Extract the Phase 1 weekly zip files directly from census.gov urls by following the below steps. There are 12 weekly files for phase 1 survey</p>\n",
    "<ul>\n",
    "<li>The function getData takes an empty dataframe, week range as input, downloads all the 12 weekly files into a dataframe and return the merged dataframe as the output</li>\n",
    "<li>Url takes the form <strong>https://www2.census.gov/programs-surveys/demo/datasets/hhp/2020/wk#/filename</strong> where # is the week number from 01 to 12 where single digit is prefixed with 0</li>\n",
    "<li>Replace the file name in the above url to  HPS_Week#_PUF_CSV.zip where # is the week number from 01 to 12</li>\n",
    "<li>Each of the url is downloaded as csv.zip file. Read the url using urlopen utility function </li>\n",
    "<li>Extract the contents using ZipFile and BytesIO modules and save the file into pandas dataframe df1</li>\n",
    "<li>Create a variable 'WEEK' in the dataframe df1 and assign it to respective week</li>\n",
    "<li>Repeat the process for all the 12 weekly files, merge all the weekly dataframes into a single dataframe df and return the df as output of the function</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(df,ver_range):\n",
    "    for l in ver_range:\n",
    "        if(l < 10):        \n",
    "            zipurl = 'https://www2.census.gov/programs-surveys/demo/datasets/hhp/2020/wk'+str(l)+'/HPS_Week0'+str(l)+'_PUF_CSV.zip'\n",
    "        else:\n",
    "            zipurl = 'https://www2.census.gov/programs-surveys/demo/datasets/hhp/2020/wk'+str(l)+'/HPS_Week'+str(l)+'_PUF_CSV.zip'\n",
    "        print(\"zipurl :\",zipurl)\n",
    "        with urlopen(zipurl) as zipresp:\n",
    "            with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                if(l < 10):\n",
    "                    df1 = pd.read_csv(zfile.open('pulse2020_puf_0'+str(l)+'.csv'))\n",
    "                else:\n",
    "                    df1 = pd.read_csv(zfile.open('pulse2020_puf_'+str(l)+'.csv'))\n",
    "                df1['WEEK'] = l\n",
    "                df = pd.concat([df,df1], axis=0, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The function <strong>getdata</strong> takes the range of weeks and an empty dataframe and returns one dataframe stored in the variable df1 that has all the 12 weeks data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_range=np.arange(1,13)\n",
    "df = pd.DataFrame()\n",
    "df1 = getData(df,ver_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get the descriptive statistics, size and shape</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>The dataset has 105 variables and 1088314 observations.</li>\n",
    "<li>Dataframe.head() gives a glimpse of top 5 observations from the dataframe df1 </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Checking for any null values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The following chunk of code does  the following</p>\n",
    "<ul><li>df1.isnull().sum() provides the count of null values in each variable of the dataframe and this is sorted in descending order and stored in the variable 'total' </li>\n",
    "<li>df1.isnull().sum()/df1.isnull().count() provides the percentage of null values for each variable of the dataframe and stored in descending order 'percent' variable </li>\n",
    "<li>Create a dataframe 'missing_data_df1' consisting of total of null values and percentage of null values in descending order</li>\n",
    "<li>Display only the values form the dataframe 'missing_data_df1' where total > 0 </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df1.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df1.isnull().sum()/df1.isnull().count()).sort_values(ascending=False)\n",
    "missing_data_df1 = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data_df1[missing_data_df1['Total'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Variables of interest</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here we remove all variables that have more than 15% of values missing and get the descriptive statistics of the remaining variables using dataframe.info()</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[missing_data_df1[missing_data_df1['Percent'] < 0.15].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing outliers </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter out records from the dataframe that are below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR where IQR is the inter quartile range, Q1 is the first quartile, Q3 is the third quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df1.quantile(0.25)\n",
    "Q3 = df1.quantile(0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[((df1 >= (Q1 - 1.5 * IQR)) & (df1 <= (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Verify if there are any duplicate records</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Engineering</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Derive new variables from existing ones  for effective interpretation and remove the redundant variables</p>\n",
    "<li>For all the new variables created, we initiate them to -99 if numeric or \"\" if string</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive a new variable RACE_ETHNICITY from RHISPANIC and RRACE based on the values each of these 2 variables can take. As per Data dictionary, if RHISPANIC is 2, then Race/Ethnicity is Hispanic else 'non Hispanic'. \n",
    "Similarly, RRACE can take values in the range 1-4 and definition of each of the races is provided in the data dictionary\n",
    "1) White, Alone\n",
    "2) Black, Alone\n",
    "3) Asian, Alone\n",
    "4) Any other race alone, or race in combination</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['RACE_ETHNICITY'] = \"\"\n",
    "df1.loc[df1.RHISPANIC == 2,'RACE_ETHNICITY'] = \"Hispanic\"\n",
    "df1.loc[(df1.RHISPANIC == 1) & (df1.RRACE == 1),'RACE_ETHNICITY'] = \"White alone\"\n",
    "df1.loc[(df1.RHISPANIC == 1) & (df1.RRACE == 2),'RACE_ETHNICITY'] = \"Black alone\"\n",
    "df1.loc[(df1.RHISPANIC == 1) & (df1.RRACE == 3),'RACE_ETHNICITY'] = \"Asian alone\"\n",
    "df1.loc[(df1.RHISPANIC == 1) & (df1.RRACE == 4),'RACE_ETHNICITY'] = \"Other races\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive a new variable EMPLOSSCOVID from RSNNOWRK. 'RSNNOWRK' = [2,3,4,5,13,8,9,10,11] is associated with Employment loss due to covid. \n",
    "As per data dictionary, RSNNOWRK can be one of the following options 1) I did not want to be employed at this time; \n",
    "2) I did not work because I am/was sick with coronavirus symptoms; \n",
    "3) I did not work because I am/was caring for someone with coronavirus symptoms; \n",
    "4) I did not work because I am/was caring for children not in school or daycare; \n",
    "5) I did not work because I am/was caring for an elderly person; \n",
    "6) I am/was sick (not coronavirus related) or disabled; \n",
    "7) I am retired; \n",
    "8) I did not have work due to coronavirus pandemic related reduction in business (including furlough); \n",
    "9) I am/was laid off due to coronavirus pandemic; \n",
    "10) My employment closed temporarily due to the coronavirus pandemic; \n",
    "11) My employment went out of business due to the coronavirus pandemic; \n",
    "12) Other reason, please specify)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['EMPLOSSCOVID'] = -99\n",
    "df1.loc[df1['RSNNOWRK'].isin([2,3,4,5,13,8,9,10,11]),'EMPLOSSCOVID'] = 1\n",
    "df1.loc[df1['RSNNOWRK'].isin([1,6,7,12]),'EMPLOSSCOVID'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive a new variable EMP_STATUS from ANYWORK. As per data dictionary, ANYWORK is the Employment status for last 7 days and takes one of the values\n",
    "1) Yes\n",
    "2) No</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['EMP_STATUS'] = -99\n",
    "df1.loc[(df1.ANYWORK==1),'EMP_STATUS'] = 1 # EMPLOYED\n",
    "df1.loc[(df1.ANYWORK==2),'EMP_STATUS'] = 0 # NOT EMPLOYED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>If EGENDER is 1, then we tranform that to MALE as per the data dictionary, else if EGENDER is 2, then FEMALE, else OTHER</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[(df1.EGENDER == 1),'EGENDER'] = \"MALE\"\n",
    "df1.loc[(df1.EGENDER == 2),'EGENDER'] = \"FEMALE\"\n",
    "df1.loc[~df1['EGENDER'].isin(['MALE','FEMALE']),'EGENDER'] = \"OTHER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive a new variable FOOD_INSUFF from CURFOODSUF which is the Household food sufficiency for last 7 days and PRIFOODSUF which is the Food Sufficiency prior to March 13, 2020</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['FOOD_INSUFF'] = -99\n",
    "df1.loc[(df1.CURFOODSUF > df1.PRIFOODSUF),'FOOD_INSUFF'] = 1\n",
    "df1.loc[(df1.CURFOODSUF <= df1.PRIFOODSUF),'FOOD_INSUFF'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>If medical care is delayed in last 4 weeks due to pandemic or did not get medical care for something not related to pandemic, then we infer that overall medical delay 'MED_DELAY' is true else false</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['MED_DELAY'] = -99\n",
    "df1.loc[((df1['DELAY'] == 1) | (df1['NOTGET']  == 1)),'MED_DELAY'] = 1\n",
    "df1.loc[((df1['DELAY'] == 2) & (df1['NOTGET']  == 2)),'MED_DELAY'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive insured status from  Health Insurance Coverage indicators HLTHINS1-6 as provided in the data dictionary </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['INSURED'] = -99\n",
    "df1.loc[(df1.HLTHINS1==1) | (df1.HLTHINS2==1) | (df1.HLTHINS5==1),'INSURED'] = 1\n",
    "df1.loc[(df1.HLTHINS1==2) | (df1.HLTHINS2==2) | (df1.HLTHINS5==2),'INSURED'] = 0 #\"PRIV-UNINS\"\n",
    "df1.loc[(df1.HLTHINS3==1) | (df1.HLTHINS4==1) | (df1.HLTHINS6==1),'INSURED'] = 1\n",
    "df1.loc[(df1.HLTHINS3==2) | (df1.HLTHINS4==2) | (df1.HLTHINS6==2),'INSURED'] = 0 #\"PUB-UNINS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive Age group from birth year</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['AGE_GROUP'] = \"\"\n",
    "df1.loc[(df1.TBIRTH_YEAR >= 1996),'AGE_GROUP'] = \"18 - 24\"\n",
    "df1.loc[(df1.TBIRTH_YEAR >= 1981) & (df1.TBIRTH_YEAR <= 1995),'AGE_GROUP'] = \"25 - 39\"\n",
    "df1.loc[(df1.TBIRTH_YEAR >= 1966) & (df1.TBIRTH_YEAR <= 1980),'AGE_GROUP'] = \"40 - 54\"\n",
    "df1.loc[(df1.TBIRTH_YEAR >= 1956) & (df1.TBIRTH_YEAR <= 1965),'AGE_GROUP'] = \"55 - 64\"\n",
    "df1.loc[(df1.TBIRTH_YEAR <= 1955),'AGE_GROUP'] = \"65 and above\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive education 'EDUC' from variable EEDUC which can take on of the following values     \n",
    "1) Less than high school\n",
    "2) Some high school\n",
    "3) High school graduate or equivalent (for example GED)\n",
    "4) Some college, but degree not received or is in progress\n",
    "5) Associate’s degree (for example AA, AS)\n",
    "6) Bachelor's degree (for example BA, BS, AB)\n",
    "7) Graduate degree (for example master's, professional, doctorate)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['EDUC'] = \"\"\n",
    "df1.loc[(df1.EEDUC >= 1) & (df1.EEDUC <= 2),'EDUC'] = \"Less than a high school diploma\"\n",
    "df1.loc[(df1.EEDUC == 3) ,'EDUC'] = \"High school diploma or GED\"\n",
    "df1.loc[(df1.EEDUC >= 4) & (df1.EEDUC <= 5),'EDUC'] = \"Some college/associate's degree\"\n",
    "df1.loc[(df1.EEDUC >= 6) & (df1.EEDUC <= 7),'EDUC'] = \"Bachelor's degree or higher\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive RENT_DEBT from TENURE and MORTLMTH. TENURE is Housing owned or rented and takes one of the following values:\n",
    "1) Owned free and clear?\n",
    "2) Owned with a mortgage or loan (including home equitly loans)?\n",
    "3) Rented?\n",
    "4) Occupied without payment of rent?\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['RENT_DEBT'] = -99\n",
    "df1.loc[(df1.TENURE.isin([2,3])) & (df1.MORTLMTH==1),'RENT_DEBT'] = 0\n",
    "df1.loc[(df1.TENURE.isin([2,3])) & (df1.MORTLMTH==2),'RENT_DEBT'] = 1\n",
    "df1.loc[(df1.TENURE.isin([2,3])) & (df1.MORTLMTH==3),'RENT_DEBT'] = 1\n",
    "df1.loc[(df1.TENURE.isin([1,4])),'RENT_DEBT'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive Education disruptions from ENROLL and TEACH variables</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['EDUC_DISRUPT'] = -99\n",
    "df1.loc[(df1.ENROLL1==1) & ((df1.TEACH2==1) | (df1.TEACH3==1)),'EDUC_DISRUPT'] = 0\n",
    "df1.loc[(df1.ENROLL1==1) & (df1.TEACH1==1),'EDUC_DISRUPT'] = 1\n",
    "df1.loc[(df1.ENROLL1==1) & (df1.TEACH4==1),'EDUC_DISRUPT'] = 0\n",
    "df1.loc[(df1.ENROLL1==1) & (df1.TEACH5==1),'EDUC_DISRUPT'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive FOOD_INSUFF_REASN from FOODSUFRSN2-5.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['FOOD_INSUFF_REASN'] = \"OTHER\"\n",
    "df1.loc[(df1.FOODSUFRSN2==1) | (df1.FOODSUFRSN3==1) | (df1.FOODSUFRSN4==1) | (df1.FOODSUFRSN5==1),'FOOD_INSUFF_REASN'] = \"COVID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive INCOME_LEV from INCOME</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['INCOME_LEV'] = \"\"\n",
    "df1.loc[df1.INCOME== 1,'INCOME_LEV'] = \"Less than $25,000\"\n",
    "df1.loc[(df1.INCOME.isin([2,3,4])),'INCOME_LEV'] = \"$25,000 - $74,999\"\n",
    "df1.loc[(df1.INCOME.isin([5,6])),'INCOME_LEV'] = \"$75,000 - $149,999\"\n",
    "df1.loc[(df1.INCOME.isin([7,8])),'INCOME_LEV'] = \"$150,000 and above\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive ANXIETY_DEPRESSION from ANXIOUS and DOWN indicators. ANXIOUS is Frequency of anxiety over previous 7 days and can take values\n",
    "1) Not at all\n",
    "2) Several days\n",
    "3) More than half the days\n",
    "4) Nearly every day. DOWN is the Frequency of feeling depressed over previous 7 days  and can take the values 1) Not at all\n",
    "2) Several days\n",
    "3) More than half the days\n",
    "4) Nearly every day \n",
    "\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ANXIETY_DEPRESSION'] = \"\"\n",
    "df1.loc[((df1.ANXIOUS == 1) & (df1.DOWN == 1)),'ANXIETY_DEPRESSION'] = \"NONE\"\n",
    "df1.loc[((df1.ANXIOUS.isin([4])) & (df1.DOWN.isin([4]))),'ANXIETY_DEPRESSION'] = \"MODERATE\"\n",
    "df1.loc[((df1.ANXIOUS.isin([2,3])) & (df1.DOWN.isin([2,3]))),'ANXIETY_DEPRESSION'] = \"VERY HIGH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive INCOMELOSS from WRKLOSS which is the recent household job loss and can take the values 1) Yes\n",
    "2) No\n",
    "and EXPCTLOSS which is the Expected household job loss and can take the values 1) Yes\n",
    "2) No\n",
    ".</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['INCOMELOSS'] = -99\n",
    "df1.loc[((df1.WRKLOSS == 2) & (df1.EXPCTLOSS == 2)),'INCOMELOSS'] = 0\n",
    "df1.loc[((df1.WRKLOSS == 1) | (df1.EXPCTLOSS == 1)),'INCOMELOSS'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We convert HLTHSTATUS,INTEREST and WORRY from numeric to string equivalent for effective interpretation</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[(df1.HLTHSTATUS.isin([1,2])),'HLTHSTATUS'] = \"EXCELLENT\"\n",
    "df1.loc[(df1.HLTHSTATUS == 3),'HLTHSTATUS'] = \"FAIR\"\n",
    "df1.loc[(df1.HLTHSTATUS.isin([4,5])),'HLTHSTATUS'] = \"POOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[(df1.INTEREST == 1),'INTEREST'] = \"NONE\"\n",
    "df1.loc[(df1.INTEREST.isin([2,3])),'INTEREST'] = \"MODERATE\"\n",
    "df1.loc[(df1.INTEREST == 4),'INTEREST'] = \"VERY HIGH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[(df1.WORRY == 1),'WORRY'] = \"NONE\"\n",
    "df1.loc[(df1.WORRY.isin([2,3])),'WORRY'] = \"MODERATE\"\n",
    "df1.loc[(df1.WORRY == 4),'WORRY'] = \"VERY HIGH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We derive STATE from EST_ST which takes a numeric value for each state. This is because we want to compare WA vs other states</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['STATE'] = 'OTHER'\n",
    "df1.loc[(df1.EST_ST == 53),'STATE'] = 'WASHINGTON'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We remove the missing values for the below catergorical variables as they cannot be imputed numerically</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['HLTHSTATUS'] != -99]\n",
    "df1 = df1[df1['INTEREST'] != -99]\n",
    "df1 = df1[df1['WORRY'] != -99]\n",
    "df1 = df1[df1['ANXIETY_DEPRESSION'] != '']\n",
    "df1 = df1[df1['INCOME_LEV'] != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Impute missing values with the mean</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><strong>The below chunk of code does the following</strong>\n",
    "    <li>Identify all the columns in the dataframe that have missing/not reported values</li>\n",
    "    <li>Then for those columns, replace the missing values by the median value for that column. Medians are more robust to outliers</li>\n",
    "    <li>Get the descriptive statistics</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df1.columns[df1.isin([-88,-99,\"\"]).any()] \n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    df1.loc[df1[col].isin([-88,-99,\"\"]), col] = df1.loc[~df1[col].isin([-88,-99,\"\"]),col].median()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Elimination</h3>\n",
    "<h4>Remove all the redundant and highly correlated features from the dataframe df1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['HLTHINS1','HLTHINS2','HLTHINS3','HLTHINS4','HLTHINS5',\\\n",
    "          'HLTHINS6','HLTHINS7','SCRAM','FOODSUFRSN1','FOODSUFRSN2', 'FOODSUFRSN3', 'FOODSUFRSN4', 'FOODSUFRSN5',\\\n",
    "               'ENROLL1', 'ENROLL2','ENROLL3','TEACH1', 'TEACH2','TEACH3', 'TEACH4', 'TEACH5','HLTHINS8',\\\n",
    "               'COMP1', 'COMP2', 'COMP3','INTRNT1', 'INTRNT2', 'INTRNT3','WHEREFREE1', 'WHEREFREE2', 'WHEREFREE3',\n",
    "       'WHEREFREE4', 'WHEREFREE5', 'WHEREFREE6', 'WHEREFREE7','TENURE','MORTLMTH','RHISPANIC','RRACE','PWEIGHT',\\\n",
    "               'ANXIOUS','ANYWORK','DELAY','NOTGET','WRKLOSS','EXPCTLOSS','MED_DELAY','EST_ST','INTRNTAVAIL',\\\n",
    "               'CURFOODSUF','RSNNOWRK','PRIFOODSUF','COMPAVAIL','UNEMPPAY','TSCHLHRS', 'TTCH_HRS','KINDWORK',\\\n",
    "               'FREEFOOD','THHLD_NUMADLT','AHHLD_NUMKID','TBIRTH_YEAR','ABIRTH_YEAR','AGENDER','AHISPANIC','ARACE',\\\n",
    "                'EEDUC','AEDUC','MS','TSPNDFOOD','TSPNDPRPD','INCOME','MORTCONF','FOODCONF','DOWN','AHHLD_NUMPER','THHLD_NUMKID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_to_drop:\n",
    "    df1.drop(col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><strong>The below chunk of code does the following</strong>\n",
    "    <li>Convert categorical variables that have natural ordering associated with it into ordinal variables</li>\n",
    "    <li>The variables include 'ANXIETY_DEPRESSION','INTEREST','WORRY','HLTHSTATUS','INCOME_LEV','AGE_GROUP','EDUC'</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats= ['NONE','MODERATE','VERY HIGH']\n",
    "df1['ANXIETY_DEPRESSION'] = pd.Categorical(df1['ANXIETY_DEPRESSION'],ordered=True, categories=cats)\n",
    "df1['INTEREST'] = pd.Categorical(df1['INTEREST'],ordered=True, categories=cats)\n",
    "df1['WORRY'] = pd.Categorical(df1['WORRY'],ordered=True, categories=cats)\n",
    "\n",
    "cats = ['POOR', 'FAIR','EXCELLENT']\n",
    "df1['HLTHSTATUS'] = pd.Categorical(df1['HLTHSTATUS'],ordered=True, categories=cats)\n",
    "\n",
    "cats = ['Less than $25,000','$25,000 - $74,999','$75,000 - $149,999','$150,000 and above']\n",
    "df1['INCOME_LEV'] = pd.Categorical(df1['INCOME_LEV'],ordered=True, categories=cats)\n",
    "\n",
    "cats = ['18 - 24','25 - 39','40 - 54', '55 - 64','65 and above']\n",
    "df1['AGE_GROUP'] = pd.Categorical(df1['AGE_GROUP'],ordered=True, categories=cats)\n",
    "\n",
    "cats=['Less than a high school diploma','High school diploma or GED',\\\n",
    "      \"Some college/associate's degree\",\"Bachelor's degree or higher\"]\n",
    "df1['EDUC'] = pd.Categorical(df1['EDUC'],ordered=True, categories=cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Build a correlation plot to make sure there are no highly correlated variable showing up</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df1.corr()\n",
    "sns.set(font_scale=3)\n",
    "f, ax = plt.subplots(figsize=(50,50))\n",
    "sns_plot = sns.heatmap(correlations,annot=True)\n",
    "\n",
    "sns_plot.set_yticklabels(\n",
    "    sns_plot.get_yticklabels(),\n",
    "    rotation=360\n",
    ")\n",
    "\n",
    "plt.tick_params(labelsize=30)\n",
    "plt.savefig('C:/Users/Lakshmi/Desktop/UW DataScience application/Data 512/Final project pictures/CorrelationPlot.jpg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Get the distribution of all the final set of variables from the dataframe using histograms for numerical variables and count plots for categorical variables</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.hist(bins=50, figsize=(60,40))\n",
    "plt.tick_params(labelsize=30)\n",
    "plt.savefig('C:/Users/Lakshmi/Desktop/UW DataScience application/Data 512/Final project pictures/NumericalVarDistribtuion.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(20, 35))\n",
    "plt.subplot(6,2,1)\n",
    "plt.title(\"Distribution by Race/ethnicity\", fontsize=20)\n",
    "df1.RACE_ETHNICITY.value_counts().sort_values().plot(kind='barh', fontsize=20)\n",
    "plt.subplot(6,2,2)\n",
    "plt.title(\"Distribution by Gender\", fontsize=20)\n",
    "df1.EGENDER.value_counts().sort_values().plot(kind='barh', fontsize=20)\n",
    "plt.subplot(6,2,3)\n",
    "plt.title(\"Distribution by Age_group\", fontsize=20)\n",
    "df1.AGE_GROUP.value_counts().sort_values().plot(kind='barh', fontsize=20)\n",
    "plt.subplot(6,2,4)\n",
    "plt.title(\"Distribution by Education\", fontsize=20)\n",
    "df1.EDUC.value_counts().sort_values().plot(kind='barh', fontsize=20)\n",
    "plt.subplot(6,2,5)\n",
    "plt.title(\"Distribution by Income Slab\", fontsize=20)\n",
    "df1.INCOME_LEV.value_counts().sort_values().plot(kind='barh', fontsize=20)\n",
    "plt.subplot(6,2,6)\n",
    "plt.title(\"Distribution by Health Status\", fontsize=20)\n",
    "df1.HLTHSTATUS.value_counts().sort_values().plot(kind='barh', fontsize=20)\n",
    "plt.subplot(6,2,7)\n",
    "plt.title(\"Distribution by Anxiety/Depession\", fontsize=20)\n",
    "df1.ANXIETY_DEPRESSION.value_counts().sort_values().plot(kind='barh', fontsize=20)\n",
    "plt.subplot(6,2,8)\n",
    "plt.title(\"Distribution by Worry levels\", fontsize=20)\n",
    "df1.WORRY.value_counts().sort_values().plot(kind='barh', fontsize=20)\n",
    "plt.tight_layout()\n",
    "fig.savefig('C:/Users/Lakshmi/Desktop/UW DataScience application/Data 512/Final project pictures/CategoricalVarDistribtuion.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Write the dataframe into comma seperated text file which will be used as input to Analysis.ipynb file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"C:/Users/Lakshmi/Desktop/UW DataScience application/Data 512/covid_clean_data.csv\", sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
